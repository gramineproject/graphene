# PyTorch manifest template
#
# This manifest was tested on Ubuntu 16.04 and 18.04.

libos.entrypoint = "file:{{ entrypoint }}"

# Path to the library OS
loader.preload = "file:{{ graphene.libos }}"

# Graphene log level
loader.log_level = "{{ log_level }}"

# Read application arguments directly from the command line. Don't use this on production!
loader.insecure__use_cmdline_argv = 1

# Propagate environment variables from the host. Don't use this on production!
loader.insecure__use_host_env = 1

# Overwrite some environment variables
loader.env.LD_LIBRARY_PATH = "/lib:/usr/lib:{{ arch_libdir }}:/usr/{{ arch_libdir }}"

# Default glibc files, mounted from the Runtime directory in GRAPHENEDIR
fs.mount.lib.type = "chroot"
fs.mount.lib.path = "/lib"
fs.mount.lib.uri = "file:{{ graphene.runtimedir() }}/"

# More libraries required by PyTorch
fs.mount.lib2.type = "chroot"
fs.mount.lib2.path = "{{ arch_libdir }}"
fs.mount.lib2.uri = "file:{{ arch_libdir }}"

fs.mount.usr.type = "chroot"
fs.mount.usr.path = "/usr"
fs.mount.usr.uri = "file:/usr"

# Host-level directory to NSS files required by Glibc + NSS libs
fs.mount.etc.type = "chroot"
fs.mount.etc.path = "/etc"
fs.mount.etc.uri = "file:/etc"

# Workload needs to create temporary files
fs.mount.tmp.type = "chroot"
fs.mount.tmp.path = "/tmp"
fs.mount.tmp.uri = "file:/tmp"

# PyTorch loads its pre-trained models from here
# Uncomment lines below if you want to use torchvision.model.alexnet(pretrained=True)
# fs.mount.torch.type = "chroot"
# fs.mount.torch.path = "{{ env.HOME }}/.cache/torch"
# fs.mount.torch.uri = "file:{{ env.HOME }}/.cache/torch"

# When run as `pip install --user ...`, pip installs Python packages here
fs.mount.pip.type = "chroot"
fs.mount.pip.path = "{{ env.HOME }}/.local/lib"
fs.mount.pip.uri = "file:{{ env.HOME }}/.local/lib"

# SGX general options

# Set the virtual memory size of the SGX enclave. For SGX v1, the enclave
# size must be specified during signing. If the workload needs more virtual memory
# than the enclave size, Graphene will not be able to allocate it.
#
# In particular, libtorch*.so is more than 1G, thus 4G is the minimum to make this run.
sgx.enclave_size = "4G"

# Set the maximum number of enclave threads. For SGX v1, the number of enclave
# TCSes must be specified during signing, so the application cannot use more
# threads than the number of TCSes. Note that Graphene also creates an internal
# thread for handling inter-process communication (IPC), and potentially another
# thread for asynchronous events. Therefore, the actual number of threads that
# the application can create is (sgx.thread_num - 2).
#
# We (somewhat arbitrarily) specify 128 threads for this workload.
sgx.thread_num = 128

# SGX trusted files

sgx.trusted_files.python = "file:{{ entrypoint }}"
sgx.trusted_files.runtime = "file:{{ graphene.runtimedir() }}/"
sgx.trusted_files.arch_libdir = "file:{{ arch_libdir }}/"
sgx.trusted_files.usr_arch_libdir = "file:/usr/{{ arch_libdir }}/"
sgx.trusted_files.python_dir = "file:{{ python.stdlib }}/"
sgx.trusted_files.dist = "file:{{ python.distlib }}/"
sgx.trusted_files.home_lib = "file:{{ env.HOME }}/.local/lib/"
sgx.trusted_files.python_local_lib = "file:{{
    python.get_path('stdlib', vars={'prefix': '/usr/local'}) }}"

sgx.trusted_files.script = "file:pytorchexample.py"
sgx.trusted_files.classes = "file:classes.txt"
sgx.trusted_files.image = "file:input.jpg"

# File containing the pre-trained model
# Uncomment lines below if you want to use torchvision.model.alexnet(pretrained=True)
# sgx.trusted_files.torch = "file:{{ env.HOME }}/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth"

# Pre-trained model saved as a file
sgx.trusted_files.model = "file:alexnet-pretrained.pt"

# Scratch space
sgx.allowed_files.tmp = "file:/tmp"

# APT config files
sgx.allowed_files.aptconfd = "file:/etc/apt/apt.conf.d"
sgx.allowed_files.aptconf = "file:/etc/apt/apt.conf"
sgx.allowed_files.apport = "file:/etc/default/apport"

# Name Service Switch (NSS) files (Glibc reads these files)
sgx.allowed_files.nsswitch = "file:/etc/nsswitch.conf"
sgx.allowed_files.group = "file:/etc/group"
sgx.allowed_files.passwd = "file:/etc/passwd"

# DNS hostname resolution files (Glibc reads these files)
sgx.allowed_files.hostconf = "file:/etc/host.conf"
sgx.allowed_files.hosts = "file:/etc/hosts"
sgx.allowed_files.gaiconf = "file:/etc/gai.conf"
sgx.allowed_files.resolv = "file:/etc/resolv.conf"

# System's file system table
sgx.allowed_files.fstab = "file:/etc/fstab"

sgx.nonpie_binary = 1

# Graphene optionally provides patched OpenMP runtime library that runs faster
# inside SGX enclaves (execute `make -C LibOS gcc` to generate it). Uncomment
# the lines below to use the patched library. PyTorch's SGX perf overhead
# decreases on some workloads from 25% to 8% with this patched library. Note
# that we need to preload the library because PyTorch's distribution renames
# libgomp.so to smth like libgomp-7c85b1e2.so.1, so it's not just a matter of
# searching in the Graphene's Runtime path first, but a matter of intercepting
# OpenMP functions.

# loader.env.LD_PRELOAD = "/lib/libgomp.so.1"
